# Ethical, Moral and Cultural issues
Moral, ethical, environmental and cultural implications. Read stuff and talk about it. Most of the stuff below is general knowledge and is not in the spec.

Cover A01, A02, A03

## Automation in the work force
Computers are used to increase efficiency in the work force, mainly in manufacturing and repetitive jobs like store cashiers, or factory work. Also contributes to the rise in online shopping / services.
- reduces labour costs, reducing product prices
- mostly replacing tedious and monotonous jobs
- removes chance of human error
- contributes to structural unemployment
- leads to reduced income for people whose skills become less useful
- Luddite Fallacy - in the long term technology lead to more new jobs being created than jobs lost

## AI
AI is beign invested it in at a faster rate than ever before because of its ability to replicate human learning, and to act autonomously (without human intervention). However, AI has some major pitfalls, which without understanding, can lead people into the trap of thinking it can replace human intelligence.
- Fundementally there is disconnect between any kind of emotions, intentions or wider context. In essence it is just copying and not thinking.
- For example, a person can apply past information to question where some data they are given is true, but an AI cannot.
- It can easily deceive, sounding confident when it knows very little.
  - This leads to missinformation being spread or people being convinved to do things the AI is making up.
- Requires an increadible amount of data (**Big Data** keyword)
  - This data can be stolen, unavailiable, incomplete
  - Not to mention the potential copyright infringement of using this data (copyright designs and patents act 1988)
- Requires an even geater amount of proccessing power,
  - which is increadibly harmful to the planet, wasting heat and using fossil fuels
  - and also is limited by the hardware the creator has access to
- Cognitive biases that people have can appear in AI too. AI has been know to perpetuate existing prejudices.

Bias is any kind of **systematic error**, it doesnt just have to be bigotry or prejudice. It could be **misreprentation** of reality in a set of data or just that the data set is too small (**insufficient**), or not properly formatted. **Prediction bias** is when the predicted output of an algorithm is far enough away from the actual real world output (a significant **algorithmic bias**). This means one output is favoured over another.

An algorithm with an **algorithmic bias** (has some error between it and the real world), can also produce an **ethical bias**. Training data or algorithms can be ethically removed from a problem, but still lead to this bias, affecting important desicions. Problems arise when a decision is morally ambigous or an input is too varied (from a not diverse enough data set) for it to handle.

When AI is explainable - developed in a way that lets you see how an AI comes to the decision it makes, it can be hugely beneficial, and can be used collaborativly with people.

AI is used in:
  - Medical research
  - More efficient medical diagnosis
  - Every day use - chat bots, spellcheck
  - voice recognision
  - navigation
  - surveilance and object recognision
  - pretty much anything execpt the things it can't do which is a lot of them

Generative AI is anything that produces new content, for example ChatGPT, and DALL-E 2.

## AI law
Laws should be promote the development of explanable, safe, ethical and useful AI without stifling growth or inovation. 

It is important to say that the current leaders of the field are not being reckless, they are shoeing the current state of the technology to the world and in lots of cases calling for more regulations.

With the current growth of the field, new laws and regulations are constantly being proposed and implemented to keep pace with technological advancements and address emerging challenges.

On the whole AI safety is being taken seriously by governments companies and law makers.

Misuse of AI could destabilise economies, and give authoritarial leaders power to manipulate. Other AI experts have warned about the long term rists of not considering AI saftey. Once it gets better at learning it will be able to learn simultaneously as a single sytem muhc faster than people can. Founders of AI and leaders of companies have said that AI should slow its development despite the short term benefits its provides. Its not that AI is being ethically developed right now, its that if it keeps developing it will reach existential heights.

Despite the internets bad track record with self regulation, major companies have set up agreements about the development of AI. To what extent the AI feild is actaully being regulated i'm not sure but the major companies invensting in AI (Google, Microsoft, Amazon, Meta, ...) are aproaching it cautiously are keeping AI ethical and taking steps to increase awareness and standards for AI.

Current laws in place
- General Data Protection Act of 2018 builds on the Data Protection Act of 1998. It includes a clause about AI - 'Right to explaination'.
- Canada passed AI legislation in 2022 to regulate how data is handled by AI and to encourage responsible AI development.
- Brazil has similar data laws in place
- China has more laws in place about newer AI

### The AI EU Act
Proposed in 2022, the act aims to set global standards for AI. It will categorise AI inot three main categories based on risk: minimal (e.g video game AI), limited (e.g chatbots), high (e.g hiring for jobs) and unnacceptable (e.g social score systems, and mass public biometric identification). The act is planned to be approved by the end of 2023.

Issues with the act include how to categorise the AI, since missing some parts of AI - or AI that has not been developed - will make the law have loopholes in the future

The aim is for harm to be mitigated and for inovation to not be stifled in the process.

## Automation in decision making
Automation in decision making means the application of alorithms to real life situations. The biggest example is probably in social media, where peoples interests and information is collected to feed them targeted ads. If any situations are not considered by the person designing the computer program, or comptuers are left to make their own rules, the equality and safety of people can be put in danger.
- Used in application processes, CCTV security systems and recruitment
- Algorithms inherently have biases, leading to decision making which discriminates, partucularly agaisnt already oppressed groups.
- Driveless cars need to make difficult decisions about the value of human life, and there needs to be accountability for those desicions
- Lethal Autonomous weapons - giving AI roles of power could hypothetically lead them to making unedcuated decisions costing lives. This is pretty much universally agreeded to be bad unless you are trying to start a nuclear war.

**Ethical bias** comes from algorithmic bias. It could be from a not diverse enough data set, or an ambigious problem.

Some automated systems include drones carrying medial equipment and robot vacumm cleaners. When talking about these, consider the impact on societies culture these will have and what ethical considerations there are.

UK law currently has systems in place that allow customers to have any decisions made by an automated process be reviewed by a human, for example for a loan or job applicaiton. 

## Environmental Effects
The more widly accessible technology is, the more it is produced and the more waste that gets thrown out. 
- E-waste is toxic, can contanimate water supplies or soil
- Computer parts are sometimes shipped to 3rd world countries with fewer environmental protection laws.
- Engery consuption emits greenhouses, contribuiting to global warming and reducing biodiversity in the long term.

EU charging cabble laws is a good case study for this section. (citation needed)

Technology is used in lots of ways to benefit the environment
- energy monitering in homes to reduce power usage in real-time
- Incentives to use smart vehives with less and more efficient fuel consumption / electric cars.
- Uses in scientific research, satellites and monitering plant and animal life, and the effects of climate change on the ice caps.

## Malicious and offensive communications
People use technology to keep connected regardless of location. The Malicious Communications Act 1988 punishes messages that might be indecent cause distress or be threatening. 

Stalking and harasment are much easier because of:
- Identities are easier to hide - the Internet provides a sense of anonymity beucase of its de-centralized nature
- VPN and encryption can be used to avoid detection.
- Missinformation can be spread and beleived at much faster speeds
- Personal information is easy to aquire, even if you have no technical knowledge

## Censorship
Censorship is any kind of controlling of what people can view.
- ISPs block content
- Used in schools and work to restrict what websites can be viewed
- Used by government to prevent citizen to seeing opposing political beliefs or socially unacceptable content
- Can be bypassed

## Collecting data and Privacy
Big Data is a large amount of data from a variety of sources. Used in data mining and to feed into algorithms. 

Data can be easily collected without the users consent under the investigatory powers act (2000). The telecommunications act of 1984 allows for people to criminalised through a phone call, and allows for mass surveillance, however it is hard to know to what extent data is being collected unless the authoirties at hand disclose so. This is done though monitering people's activities online, emails, messages and phone calls. Collected personal data can be pretty much anything, e.g. addresses or medical records. This has laed to major data breaches in the past when personal data has not been handled correctly. Because this breaches this the data protection act of 1998, this lead to fines to to company / council. 

Encrypted data is still valuable in the hand of attackers because of a principle know as store now, decrypt later which assumes that quantum computer will be able to crack encryption that is difficult to break now in a few decades. However encrypting data can still deter a lot of breaches.

Many people argue that mass surveilance and companies collecting data is an invasion of privacy. Sureillance data can be used a evidence to charge criminals in court, and warrent is still required (unless you are the government or ISP), although it ends up including non criminal civilians.

## Piracy
Piracy is the illegal copying of software without regard for copyright laws. The internet has made piracy more of a problem than before, since pirated files can be distributed easier. Music and video are two popular forms of content to distribute illegally and the distributer of the copryrighted content is in fault in the eyes of the law in this situation. Copyright law covers these types of media unless they have been released with a permissive license, for example a creative commons license. Sometimes these licenses are assumed which causes confusion and making it easier to specify a license for your property if you are a creator would mean less people would resort to piracy or pirate by accident. 

People should have rights over he content they create and pirating violate these rights and hurts the income of the people making the content. Music labels and streaming services need to enforce copyright to pay the artists. Piracy can also have a negative impact on people who use the content following its regulaations, such as the creators releasing thier work under more restictive licesing or making thier work more harder to aquire. 

Acording to data from the *Online copyright infringement tracker survey* published by the UK Intellectual Property Office, piracy has remained mostly constant over the past decade, at around 20% for music. With reasons being cost, conveinience and availablity. https://www.gov.uk/government/publications/online-copyright-infringement-tracker-survey-12th-wave/executive-summary-online-copyright-infringement-tracker-survey-12th-wave

## Accessibility
Websites should be designed in accordance to the Equality Act (2010) to make sure content can be accessed by people with particular needs.
- menu buttons for navigation between pages
- ability to enlarge text
- ability to increase contrast 
- some colour schemes are better for colour blindness
- colours have no set meaning
- provide alt text for images
- provide transcriptions of audio files
- be translatable (sometimes text direction needs to be fliped or rotated)
- use unicode (people may need to enter special characters for their name)
- be developed with photosensitive users in mind.
- keep in mind that different input methods and keyboard layouts exists.

## The economy 
Countries with lower GDA have less access to the internet, creating a digital divide and disadvatanging certain people. This gap has closed as more countreis gain access to the internet. 

The selling of digital goods contributes to a major part of the economy.
