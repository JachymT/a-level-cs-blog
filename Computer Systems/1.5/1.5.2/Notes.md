# Ethical, Moral and Cultural issues
Moral, ethical, environmental and cultural implications. Read stuff and talk about it. Most of the stuff below is general knowledge and is not in the spec.

Cover A01, A02, A03

## Automation in the work force
Computers are used to increase efficiency in the work force, mainly in manufacturing and repetitive jobs like store cashiers, or factory work. Also contributes to the rise in online shopping / services.
- reduces labour costs, reducing product prices
- mostly replacing tedious and monotonous jobs
- removes chance of human error
- contributes to structural unemployment
- leads to reduced income for people whose skills become less useful
- Luddite Fallacy - in the long term technology leads to more new jobs being created than jobs lost

## AI
AI is beign invested it in at a faster rate than ever before because of its ability to replicate human learning, and to act autonomously (without human intervention). However, AI has some major pitfalls, which without understanding, can lead people into the trap of thinking it can replace human intelligence.
- Fundementally there is disconnect between any kind of emotions, intentions or wider context. In essence it is just copying and not thinking.
- For example, a person can apply past information to question where some data they are given is true, but an AI cannot.
- It can easily deceive, sounding confident when it knows very little.
  - This leads to missinformation being spread or people being convinved to do things the AI is making up.
- Requires an increadible amount of data (**Big Data** keyword)
  - This data can be inaccurate, unavailiable, incomplete
  - Not to mention the potential copyright infringement of using this data (copyright designs and patents act 1988)
- Requires an even geater amount of proccessing power,
  - which is increadibly harmful to the planet, wasting heat and using fossil fuels
  - and also is limited by the hardware the creator has access to
- Bias is easy to introduce and hard to spot and remove

### Bias
Bias is any kind of **systematic error**, it doesnt just have to be bigotry or prejudice. **Algorithmic bias** is when some error in an algorithm causes it incorrectly favour one output over another. This leads to unfair, unintended outputs. The significance of an **algorithmic bias** can be quantified by looking at **prediction bias** - the error between a prediction and the real world output.

Causes of algorithmic bias. The most obvious cause of algorithmic bias is data. When ML algorithms are trained on data, they will be fine tuned to that set of dat. Even if the training data is ethically removed from a problem (which it ussually is), it could lead to a bias. Furthermore an AI is not alwasy looking for a objective answer, and a decision could be morally ambigious or hard to calssiffy.

The data set could be
- **imblanaced** - not representing all subsets of the data equally
- **insufficient** or not diverse enough - too small
- not properly formated / cleaned
- incorrect / have a pre-existing bias - be misrepesenting reality
- using data that is categorised and sorted either by people or for people.

These make an AI inaccurate

An algorithm with an **algorithmic bias** can produce an **ethical bias** or **social bias**. Bias can enter into systems from pre-existing social, cultural and insitutional expectations, as well as from technical design flaws, or when the AI is used for a purpose outside what it was made for. When AI categories information in new ways it can lead to unexpected correlations and outcomes, (see automation in decision making). Cognitive biases in people have can appear in AI that they create, for example when choosing data , which is why it is important for people to take responsibilty and accountability for AI. Most commenly systematic and unfair discrimination is caused by an AI learning innacurate steriotypes about often already discriminted groups and perpetuating social and economic biases that it sees. For example, oftering single mothers higher interst rates based on credit card scores (again, see automation in decision making). When a group is underrepresned or represnted poorly in data, a biased algorthim could disregard data from that group, sucha as creating criteria that remove certain results. For example bias towards bananas could show them at the top of list of results for the search "fuits", and not show any oranges at all.

Adidtionally, finding a bias is hard because algorithms are often propreitary and kept under warps and are often very complex, and take into account multiple inputs often processed by other algorithms (see explainable AI). Other than handing the training data better, bias can be removed throught the use of filters, however if these are not used correctly they could either be bypassed or introduce further bias.

### Uses
AI is used in:
  - Medical research
  - More efficient medical diagnosis
  - Every day use - chat bots, spellcheck
  - voice recognision
  - navigation
  - search engines
  - surveilance and object recognision
  - pretty much anything execpt the things it can't do which is a lot of them

Generative AI is anything that produces new content, for example ChatGPT, and DALL-E 2. Current geenrative AI does not have the nuance or understanding for tasks such as a writing high quality essays, or giving advice to medical patients or potentially vunerable people. In the past, generative AI has given out of date information and dangerous advice when used as a medical chatbot.

## AI law
Whilst the AI industry is self regulating to some extent, they are also putting more pressure on law makers (governments) to take AI safety seriously. With the current growth of the field, new laws and regulations are constantly being proposed and implemented to keep pace with technological advancements and address emerging challenges.

The current goals of AI laws are:
- promote the development of explanable, safe, ethical and useful AI
- mitage harm that AI could be used to cause 
- without stifling growth or inovation
- take into acount the current state of the technology
- prevent misuse that could give power to manipulate the economy of public opinions
- slow down AI development slightly, despite the short term benefits
- avoid an existential catastrophy pretty much (unlikly, but its heading in that direction)
- prevent unregulated use of AI on the internet to create disinformation
- tackle algorithmic bias in AI, esspecially where it leads to prejudice

When AI is **explainable** - developed in a way that lets you see how an AI comes to the decision it makes, it can be hugely beneficial, and can be used collaborativly with people.

Current laws in place
- General Data Protection Act of 2018 builds on the Data Protection Act of 1998. It includes a clause about AI - 'Right to explaination'.
- Canada passed AI legislation in 2022 to regulate how data is handled by AI and to encourage responsible AI development.
- Brazil has similar data laws in place
- China has more laws in place about newer AI
- major companies in AI (Google, Microsoft, Amazon, Meta, ...) have set up agreements to keep AI ethical developement ethical and are taking steps to increase awareness and standards for AI.

### The EU AI Act case study
Proposed in 2022, the act aims to set global standards for AI. It will categorise AI inot three main categories based on risk: minimal (e.g video game AI), limited (e.g chatbots), high (e.g hiring for jobs) and unnacceptable (e.g social score systems, and mass public biometric identification). The act is planned to be approved by the end of 2023.

Issues with the act include how to categorise the AI, since missing some parts of AI - or AI that has not been developed yet - could introduce loopholes in the future.

## Automation in decision making
Automation in decision making means the application of alorithms to real life situations. The biggest example is probably in social media, where peoples interests and information is collected to feed them targeted ads. If any situations are not considered by the person designing the computer program, or comptuers are left to make their own rules, the equality and safety of people can be put in danger.
- Used in application processes, CCTV security systems and recruitment
- Algorithms inherently have biases, leading to decision making which discriminates, partucularly agaisnt already oppressed groups.
- Driveless cars need to make difficult decisions about the value of human life, and there needs to be accountability for those desicions
- Lethal Autonomous weapons - giving AI roles of power could hypothetically lead them to making unedcuated decisions costing lives. This is pretty much universally agreeded to be bad unless you are trying to start a nuclear war.

**Ethical bias** comes from algorithmic bias. It could be from a not diverse enough data set, or an ambigious problem.

Some automated systems include drones carrying medial equipment and robot vacumm cleaners. When talking about these, consider the impact on societies culture these will have and what ethical considerations there are.

UK law currently has systems in place that allow customers to have any decisions made by an automated process be reviewed by a human, for example for a loan or job applicaiton. 

## Environmental Effects
The more widly accessible technology is, the more it is produced and the more waste that gets thrown out. 
- E-waste is toxic, can contanimate water supplies or soil
- Computer parts are sometimes shipped to 3rd world countries with fewer environmental protection laws.
- Engery consuption emits greenhouses, contribuiting to global warming and reducing biodiversity in the long term.

Technology is used in lots of ways to benefit the environment
- energy monitering in homes to reduce power usage in real-time
- Incentives to use smart vehives with less and more efficient fuel consumption / electric cars.
- Uses in scientific research, satellites and monitering plant and animal life, and the effects of climate change on the ice caps.

### EU charging cable law case study
A factor that caused the European Commission to pass its common charger law in June of 2022 is the waste produced from charging cables. According to reasearch by the European Commission, 11,000 tonnes of charging cables go to waste every year.

By the end of 2024 all smartphones (and other small sized devices) sold in Europe must use USB-C, and devices will not come with charing cables unless opted for. The law is future proofed for the day when UBS-C is replaced with a new standard. The re-use of charging cables will also same consumers money.

The law shows that E-waste is a significant issue and could force companies using propreitery technology to change to be more sustainable globally. Execessive production of electronic devices with the aim of locking consumers into a propreity system, when exisiting solutions exist, causes irreversable damadge to the environment.

## Malicious and offensive communications
People use technology to keep connected regardless of location. The Malicious Communications Act 1988 punishes messages that might be indecent cause distress or be threatening. 

Stalking and harasment are much easier because of:
- Identities are easier to hide - the Internet provides a sense of anonymity beucase of its de-centralized nature
- VPN and encryption can be used to avoid detection.
- Missinformation can be spread and beleived at much faster speeds
- Personal information is easy to aquire, even if you have no technical knowledge

## Censorship
Censorship is any kind of controlling of what people can view.
- ISPs block content
- Used in schools and work to restrict what websites can be viewed
- Used by government to prevent citizen to seeing opposing political beliefs or socially unacceptable content
- Can be bypassed

## Collecting data and Privacy
Big Data is a large amount of data from a variety of sources. Used in data mining and to feed into algorithms. 

Data can be easily collected without the users consent under the investigatory powers act (2000). The telecommunications act of 1984 allows for people to criminalised through a phone call, and allows for mass surveillance, however it is hard to know to what extent data is being collected unless the authoirties at hand disclose so. This is done though monitering people's activities online, emails, messages and phone calls. Collected personal data can be pretty much anything, e.g. addresses or medical records. This has lead to major data breaches in the past when personal data has not been handled correctly. Because this breaches this the data protection act of 1998, this lead to fines to the organisation responsible. 

Can be prevented to some extent by encrypting your data and messages, and using a VPN to mask your IP. Encrypted data is still valuable in the hand of attackers because of a principle know as store now, decrypt later which assumes that quantum computer will be able to crack encryption that is difficult to break now in a few decades. However encrypting data can still deter a lot of breaches.

Many people argue that mass surveilance and companies collecting data is an invasion of privacy. Sureillance data can be used a evidence to charge criminals in court, and warrent is still required (unless you are the government or ISP), although it ends up including non criminal civilians. Mass surveilance would catch more criminals but you'd also get a lot of false positives.

## Piracy
Piracy is the illegal copying of software without regard for copyright laws. The internet has made piracy more of a problem than before, since pirated files can be distributed easier. Music and video are two popular forms of content to distribute illegally and the distributer of the copryrighted content is in fault in the eyes of the law in this situation. Copyright law covers these types of media unless they have been released with a permissive license, for example a creative commons license. Sometimes these licenses are assumed which causes confusion and making it easier to specify a license for your property if you are a creator would mean less people would resort to piracy or pirate by accident. 

People should have rights over he content they create and pirating violate these rights and hurts the income of the people making the content. Music labels and streaming services need to enforce copyright to pay the artists. Piracy can also have a negative impact on people who use the content following its regulaations, such as the creators releasing thier work under more restictive licesing or making thier work more harder to aquire. 

Acording to data from the *Online copyright infringement tracker survey* published by the UK Intellectual Property Office, piracy has remained mostly constant over the past decade, at around 20% for music. With reasons being cost, conveinience and availablity. https://www.gov.uk/government/publications/online-copyright-infringement-tracker-survey-12th-wave/executive-summary-online-copyright-infringement-tracker-survey-12th-wave

## Accessibility
Websites should be designed in accordance to the Equality Act (2010) to make sure content can be accessed by people with particular needs.
- menu buttons for navigation between pages
- ability to enlarge text
- ability to increase contrast 
- some colour schemes are better for colour blindness
- colours have no set meaning
- provide alt text for images
- provide transcriptions of audio files
- be translatable (sometimes text direction needs to be fliped or rotated)
- use unicode (people may need to enter special characters for their name)
- be developed with photosensitive users in mind.
- keep in mind that different input methods and keyboard layouts exists.

## The economy 
Countries with lower GDA have less access to the internet, creating a digital divide and disadvatanging certain people. This gap has closed as more countreis gain access to the internet. 

The selling of digital goods contributes to a major part of the economy.
